---
title: "Enable GPU support | Docker Docs"
source_url: "https://docs.docker.com/compose/how-tos/gpu-support/"
scraped_date: "2025-08-19T12:58:07.717084"
description: "Learn how to configure Docker Compose to use NVIDIA GPUs with CUDA-based containers"
keywords: "documentation,docs,docker,compose,GPU,access,NVIDIA,samples"
---
# Enable GPU support | Docker Docs

Back Ask AI Start typing to search or try Ask AI.Contact support Manuals Get startedGuidesReferenceOpen sourceDocker Engine Install UbuntuDebianRHELFedoraRaspberry Pi OS (32-bit)CentOSSLES (s390x)BinariesPost-installation stepsStorage VolumesBind mountstmpfs mountsStorage drivers Select a storage driverBTRFS storage driverDevice Mapper storage driver (deprecated)OverlayFS storage driverVFS storage driverwindowsfilter storage driverZFS storage drivercontainerd image storeNetworking Packet filtering and firewallsNetwork drivers Bridge network driverHost network driverIPvlan network driverMacvlan network driverNone network driverOverlay network driver Tutorials Networking using a macvlan networkNetworking using the host networkNetworking with overlay networksNetworking with standalone containersCA certificatesLegacy container links Containers Start containers automaticallyRun multiple processes in a containerResource constraintsRuntime metricsRunning containers CLI CompletionProxy configurationFilter commandsFormat command and log outputOpenTelemetry for the Docker CLIDaemon Start the daemonUse IPv6 networkingDaemon proxy configurationLive restoreAlternative container runtimesCollect Docker metrics with PrometheusConfigure remote access for Docker daemonRead the daemon logsTroubleshooting the Docker daemon Manage resources Docker contextsDocker object labelsPrune unused Docker objectsLogs and metrics Configure logging driversCustomize log driver output Logging drivers Amazon CloudWatch Logs logging driverETW logging driverFluentd logging driverGoogle Cloud Logging driverGraylog Extended Format logging driverJournald logging driverJSON File logging driverLocal file logging driverSplunk logging driverSyslog logging driverUse a logging driver pluginUse docker logs with remote logging driversSecurity Rootless modeAntivirus software and DockerAppArmor security profiles for DockerContent trust in Docker Automation with content trustDelegations for content trustDeploy Notary Server with ComposeManage keys for content trustPlay in a content trust sandboxDocker security non-eventsIsolate containers with a user namespaceProtect the Docker daemon socketSeccomp security profiles for DockerVerify repository client with certificatesSwarm mode Administer and maintain a swarm of Docker EnginesDeploy a stack to a swarmDeploy services to a swarmGetting started with Swarm mode Create a swarmAdd nodes to the swarmDeploy a service to the swarmInspect a service on the swarmScale the service in the swarmDelete the service running on the swarmApply rolling updates to a serviceDrain a node on the swarm How swarm works How nodes workHow services workManage swarm security with public key infrastructure (PKI)Swarm task statesJoin nodes to a swarmLock your swarm to protect its encryption keyManage nodes in a swarmManage sensitive data with Docker secretsManage swarm service networksRaft consensus in swarm modeRun Docker Engine in swarm modeStore configuration data using Docker ConfigsSwarm mode key conceptsUse Swarm mode routing meshDeprecated featuresDocker Engine plugins Access authorization pluginDocker log driver pluginsDocker network driver pluginsDocker Plugin APIDocker volume pluginsPlugin Config Version 1 of Plugin V2Use Docker Engine plugins Release notes Engine v28Engine v27Engine v26.1Engine v26.0Engine v25.0Engine v24.0Engine v23.0Engine v20.10Engine v19.03Engine v18.09Engine v18.06Engine v18.05Engine v18.04Engine v18.03Engine v18.02Engine v18.01Engine v17.12Engine v17.11Engine v17.10Engine v17.09Engine v17.07Engine v17.06Engine v17.05Engine v17.04Engine v17.03Prior releasesDocker Build Core concepts Docker Build OverviewDockerfile overviewBuild context Building Multi-stageVariablesSecretsMulti-platformExport binariesContainer Device Interface (CDI)Best practicesBase imagesBuild checks NewBuilders Build drivers Docker container driverDocker driverKubernetes driverRemote driverManage buildersBake IntroductionTargetsInheritanceVariablesExpressionsFunctionsMatrix targetsContextsBake file referenceBake standard library functionsBuilding with Bake from a Compose fileOverriding configurationsRemote Bake file definitionCache Build cache invalidationBuild garbage collectionCache storage backends Amazon S3 cacheAzure Blob Storage cacheGitHub Actions cacheInline cacheLocal cacheRegistry cacheOptimize cache usage in buildsCI GitHub Actions AnnotationsAttestationsBuild checksBuild secretsBuild summaryBuildKit configurationCache managementCopy image between registriesExport to DockerLocal registryMulti-platform imageNamed contextsPush to multiple registriesReproducible buildsShare image between jobsTags and labelsTest before pushUpdate Docker Hub description Metadata AnnotationsBuild attestations Image attestation storageProvenance attestationsSBOM attestationsSLSA definitionsExporters Image and registry exportersLocal and tar exportersOCI and Docker exportersBuildKit buildkitd.tomlConfigure BuildKitCustom Dockerfile syntaxDockerfile release notes Debugging OpenTelemetry supportBuild release notesDocker Compose Introduction to Compose How Compose worksWhy use Compose?History and developmentInstall PluginStandaloneUninstallQuickstart How-tos Specify a project nameUse lifecycle hooksUse service profilesControl startup orderUse environment variables Set environment variablesEnvironment variables precedencePre-defined environment variablesInterpolationBest practicesBuild dependent imagesUse Compose WatchSecrets in ComposeNetworkingUse multiple Compose files MergeExtendIncludeEnable GPU supportUse Compose in productionOCI artifact applications NewUse provider services NewCompose Bridge UsageCustomize Support and feedback FAQsGive feedbackSample apps Releases Release notesMigrate to Compose v2MCP Gateway TestcontainersAIAsk Gordon Beta Model Context Protocol (MCP) Built-in tools in GordonConfigure MCP servers with YAMLDocker Model Runner Beta Get started with DMRDMR REST APIDMR examplesMCP Catalog and Toolkit Beta Docker Hub MCP serverDocker MCP CatalogMCP Toolkit AI and Docker Compose Use AI models in Compose NewProductsDocker Desktop Setup Install MacMac permission requirementsWindowsWindows permission requirementsLinux UbuntuDebianFedoraArchRHELVM or VDI environmentsSign inAllowlistExplore Docker Desktop ContainersImagesVolumesBuildsResource Saver modePause Docker Desktop Features and capabilities NetworkingGPU supportUSB/IP supportDeploy on KubernetesSynchronized file sharescontainerd image storeWasm workloads BetaDocker Desktop CLIVirtual Machine ManagerWSL Best practicesCustom kernels on WSLUse WSL Settings and maintenance Change settingsBackup and restore data Troubleshoot and support Troubleshoot and diagnose Common topicsKnown issuesGet support for Docker Desktop FAQs GeneralMacWindowsLinuxReleasesGive feedbackUninstallFix startup issue for MacRelease notesDocker Hardened Images New QuickstartAbout Hardened imagesImage typesImage testingResponsibility overviewFeatures FlexibilityContinuous patchingEnterprise supportHardened, secure imagesSeamless integrationHow-tos Explore imagesMirror an imageCustomize an imageUse an imageVerify an imageManage imagesScan an imageEnforce image usageMigrate an appDebug a containerCore concepts AttestationsCIS BenchmarkCode signingCVEsDistroless imagesFIPSglibc and muslHardeningImage digestsImage provenanceImmutabilitySBOMsSLSASoftware Supply Chain SecuritySSDLCSTIGVEXTroubleshootDocker Offload Beta QuickstartAboutConfigureUsage & billingOptimize usageTroubleshootGive feedbackDocker Build Cloud SetupUsageContinuous integrationOptimizationBuilder settingsRelease notesDocker Hub QuickstartLibrary SearchTrusted contentCatalogsMirrorRepositories Create Manage Repository informationAccessImages TagsImmutable tagsImage ManagementSoftware artifactsPush imagesMove imagesImage security insightsWebhooksAutomated builds Set upLink accountsAutomated repository testsAdvanced optionsManage autobuildsTroubleshootTrusted content Docker Official ImagesDocker Verified Publisher ProgramDocker-Sponsored Open Source ProgramInsights and analyticsArchiveDeletePersonal settingsUsage and limits PullsOptimize usageService accountsTroubleshootRelease notesDocker Scout InstallQuickstart Explore DashboardDocker Scout image analysisDocker Scout metrics exporterImage details viewManage vulnerability exceptions How-tos Create an exception using the GUICreate an exception using the VEXDocker Scout environment variablesDocker Scout SBOMsUse Scout with different artifact types Deep dive Advisory database sources and matching serviceData collection and storage in Docker ScoutPolicy Evaluation Configure policiesDocker Scout health scoresEvaluate policy compliance in CIRemediation with Docker ScoutView Docker Scout policy statusIntegrations Code quality SonarQube Container registries Amazon ECRAzure Container RegistryContinuous Integration Azure DevOps PipelinesCircle CIGitHub ActionsGitLab CI/CDJenkinsIntegrating Docker Scout with environments Generic (CLI)Sysdig Source code management GitHub Team collaboration Slack Release notes CLI release notesPlatform release notesDocker for GitHub Copilot EA InstallUsageExample promptsDocker Extensions Marketplace extensionsNon-marketplace extensionsConfigure a private marketplaceSettings and feedbackExtensions SDK The build and publish processQuickstart Part one: Build Create a simple extensionCreate an advanced frontend extensionAdd a backend to your extensionPart two: Publish Add labelsValidatePackage and release your extensionShare your extensionPublish in the MarketplaceBuild multi-arch extensionsArchitecture MetadataSecurityDesign and UI styling GuidelinesDocker design principlesMUI best practices Developer Guides AuthenticationInteracting with KubernetesInvoke host binariesUse the Docker socket Developer SDK tools Test and debugContinuous Integration (CI)CLI reference Extension APIs DashboardDockerExtension BackendExtension UI APINavigationTestcontainers CloudDeprecated products and featuresRelease lifecyclePlatformBilling Add or update a payment methodManage your billing information3D Secure authenticationView billing historyChange your billing cycleSubmit a tax exemption certificateFAQsDocker accounts AccountsCreate an accountManage an accountDeactivate an accountSecurity Personal access tokensTwo-factor authentication Recover your Docker account FAQs GeneralContainerNetwork and VM Single sign-on GeneralDomainsEnforcementIdentity providersUser managementSecurity announcementsSubscription Subscriptions and featuresSet up your subscriptionScale your subscriptionManage seatsChange your subscriptionDocker Desktop license agreementFAQsRelease notesEnterpriseAdministration Organization administration Create your organizationOnboard your organizationManage organization membersConvert an account into an organizationCreate and manage a teamDeactivate an organizationManage Docker productsActivity logsOrganization informationInsightsCompany administration overview Create a companyManage company membersManage company organizationsManage company owners FAQ OrganizationCompanyDeploy Docker Desktop MSI installerPKG installerMS StoreDeploy with IntuneDeploy with Jamf ProMicrosoft Dev BoxFAQsSecurity Single sign-on ConfigureConnectManageProvision Just-in-TimeSCIMGroup mappingEnforce sign-in ConfigureRoles and permissionsManage domainsHardened Docker Desktop Enhanced Container Isolation Enable ECIConfigure advanced settingsLimitationsFAQsSettings Management Use a JSON fileUse the Admin ConsoleDesktop settings reportingSettings referenceRegistry Access ManagementImage Access ManagementAir-gapped containersOrganization access tokens Troubleshoot Troubleshoot provisioningTroubleshoot SSOHome / Manuals / Docker Compose / How-tos / Enable GPU supportRun Docker Compose services with GPU accessPage options Copy page as Markdown for LLMs View page as plain text Ask questions with Docs AI ClaudeOpen in ClaudeTable of contentsEnabling GPU access to service containersExample of a Compose file for running a service with access to 1 GPU deviceAccess specific devicesCompose services can define GPU device reservations if the Docker host contains such devices and the Docker Daemon is set accordingly. For this, make sure you install the prerequisites if you haven't already done so.The examples in the following sections focus specifically on providing service containers access to GPU devices with Docker Compose. You can use either docker-compose or docker compose commands. For more information, see Migrate to Compose V2.Enabling GPU access to service containersGPUs are referenced in a compose.yaml file using the device attribute from the Compose Deploy specification, within your services that need them.This provides more granular control over a GPU reservation as custom values can be set for the following device properties:capabilities. This value is specified as a list of strings. For example, capabilities: [gpu]. You must set this field in the Compose file. Otherwise, it returns an error on service deployment.count. Specified as an integer or the value all, represents the number of GPU devices that should be reserved (providing the host holds that number of GPUs). If count is set to all or not specified, all GPUs available on the host are used by default.device_ids. This value, specified as a list of strings, represents GPU device IDs from the host. You can find the device ID in the output of nvidia-smi on the host. If no device_ids are set, all GPUs available on the host are used by default.driver. Specified as a string, for example driver: 'nvidia'options. Key-value pairs representing driver specific options. ImportantYou must set the capabilities field. Otherwise, it returns an error on service deployment. Notecount and device_ids are mutually exclusive. You must only define one field at a time.For more information on these properties, see the Compose Deploy Specification.Example of a Compose file for running a service with access to 1 GPU device services: test: image: nvidia/cuda:12.9.0-base-ubuntu22.04 command: nvidia-smi deploy: resources: reservations: devices: - driver: nvidia count: 1 capabilities: [gpu]Run with Docker Compose: $ docker compose up Creating network "gpu_default" with the default driver Creating gpu_test_1 ... done Attaching to gpu_test_1 test_1 | +-----------------------------------------------------------------------------+ test_1 | | NVIDIA-SMI 450.80.02 Driver Version: 450.80.02 CUDA Version: 11.1 | test_1 | |-------------------------------+----------------------+----------------------+ test_1 | | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | test_1 | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | test_1 | | | | MIG M. | test_1 | |===============================+======================+======================| test_1 | | 0 Tesla T4 On | 00000000:00:1E.0 Off | 0 | test_1 | | N/A 23C P8 9W / 70W | 0MiB / 15109MiB | 0% Default | test_1 | | | | N/A | test_1 | +-------------------------------+----------------------+----------------------+ test_1 | test_1 | +-----------------------------------------------------------------------------+ test_1 | | Processes: | test_1 | | GPU GI CI PID Type Process name GPU Memory | test_1 | | ID ID Usage | test_1 | |=============================================================================| test_1 | | No running processes found | test_1 | +-----------------------------------------------------------------------------+ gpu_test_1 exited with code 0 On machines hosting multiple GPUs, the device_ids field can be set to target specific GPU devices and count can be used to limit the number of GPU devices assigned to a service container.You can use count or device_ids in each of your service definitions. An error is returned if you try to combine both, specify an invalid device ID, or use a value of count that’s higher than the number of GPUs in your system. $ nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 450.80.02 Driver Version: 450.80.02 CUDA Version: 11.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla T4 On | 00000000:00:1B.0 Off | 0 | | N/A 72C P8 12W / 70W | 0MiB / 15109MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ | 1 Tesla T4 On | 00000000:00:1C.0 Off | 0 | | N/A 67C P8 11W / 70W | 0MiB / 15109MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ | 2 Tesla T4 On | 00000000:00:1D.0 Off | 0 | | N/A 74C P8 12W / 70W | 0MiB / 15109MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ | 3 Tesla T4 On | 00000000:00:1E.0 Off | 0 | | N/A 62C P8 11W / 70W | 0MiB / 15109MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ Access specific devicesTo allow access only to GPU-0 and GPU-3 devices: services: test: image: tensorflow/tensorflow:latest-gpu command: python -c "import tensorflow as tf;tf.test.gpu_device_name()" deploy: resources: reservations: devices: - driver: nvidia device_ids: ['0', '3'] capabilities: [gpu] Edit this page Request changesTable of contentsEnabling GPU access to service containersExample of a Compose file for running a service with access to 1 GPU deviceAccess specific devices